{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import re\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df = pd.DataFrame(columns=['job_title', 'experience_needed', 'career_level', 'education_level', 'min_salary', 'max_salary', 'gender', 'job_categories', 'job_description', 'job_requirements', 'vacancies', 'company_name', 'location', 'job_types', 'job_skills'])\n",
    "company_df = pd.DataFrame(columns=['company_url', 'company_name', 'location', 'foundation_date', 'min_size', 'max_size', 'specialities', 'industry', 'about'])\n",
    "company_http = []\n",
    "http_links = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping all the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_job_info(url):\n",
    "    driver = webdriver.Edge()\n",
    "\n",
    "    driver.get(url)\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    try:\n",
    "        page_html = driver.page_source\n",
    "\n",
    "        soup = BeautifulSoup(page_html, 'html.parser')\n",
    "        \n",
    "        link_element = soup.select_one(\"#app > div > main > section.css-dy1y6u > div > strong.css-9geu3q > div > a\") \n",
    "        if link_element:\n",
    "            link = link_element.get('href')\n",
    "            if link not in company_http:\n",
    "                company_http.append(link)\n",
    "\n",
    "        job_title_element = soup.select_one('#app > div > main > section.css-dy1y6u > div > h1')\n",
    "        job_title = job_title_element.get_text().strip() if job_title_element else None\n",
    "\n",
    "        experience_element = soup.select_one('#app > div > main > section.css-3kx5e2 > div:-soup-contains(\"Experience Needed\") > span.css-47jx3m > span')\n",
    "        experience_text = experience_element.get_text().strip() if experience_element and experience_element.get_text() != \"Not Specified\" else None\n",
    "        experience_needed = None\n",
    "        if experience_text:\n",
    "            match = re.search(r'\\d+', experience_text)\n",
    "            if match:\n",
    "                experience_needed = match.group()\n",
    "\n",
    "        career_level_element = soup.select_one('#app > div > main > section.css-3kx5e2 > div:-soup-contains(\"Career Level\") > span.css-47jx3m > span')\n",
    "        career_level = career_level_element.get_text().strip() if career_level_element and career_level_element.get_text() != \"Not specified \" else None\n",
    "\n",
    "        education_element = soup.select_one('#app > div > main > section.css-3kx5e2 > div:-soup-contains(\"Education Level\") > span.css-47jx3m > span')\n",
    "        education_level = education_element.get_text().strip() if education_element and education_element.get_text() != \"Not Specified\" else None\n",
    "\n",
    "        gender_element = soup.select_one('#app > div > main > section.css-3kx5e2 > div:-soup-contains(\"Gender\") > span.css-47jx3m > span')\n",
    "        gender = gender_element.get_text().strip() if gender_element and gender_element.get_text() != \"Not Specified\" else None\n",
    "\n",
    "        salary_element = soup.select_one('#app > div > main > section.css-3kx5e2 > div:-soup-contains(\"Salary\") > span.css-47jx3m > span')\n",
    "        salary_text = salary_element.get_text().strip() if salary_element and salary_element.get_text() != \"Not Specified\" else None\n",
    "        min_salary = None\n",
    "        max_salary = None\n",
    "        if salary_text and (not (\"Confidential\" in salary_text)):\n",
    "            numbers = re.findall(r'\\d+', salary_text)\n",
    "            if numbers:\n",
    "                min_salary = numbers[0]\n",
    "                if len(numbers) > 1:\n",
    "                    max_salary = numbers[1]\n",
    "\n",
    "        job_categories_element = soup.select('#app > div > main > section.css-3kx5e2 > div.css-13sf2ik > ul > li')\n",
    "        job_categories = [category.get_text().strip() for category in job_categories_element] if job_categories_element else None\n",
    "\n",
    "        job_description_element = soup.select_one('#app > div > main > section:-soup-contains(\"Job Description\") > div')\n",
    "        job_description = job_description_element.get_text().strip() if job_description_element else None\n",
    "\n",
    "        job_requirements_element = soup.select_one('#app > div > main > section:-soup-contains(\"Job Requirements\") > div')\n",
    "        job_requirements = job_requirements_element.get_text().strip() if job_requirements_element else None\n",
    "\n",
    "        vacancies_element = soup.select_one('#app > div > main > section.css-dy1y6u > div > div.css-104dl8g > div > span > span:-soup-contains(\"open\")')\n",
    "        vacancies_text = vacancies_element.get_text().strip() if vacancies_element and vacancies_element.get_text() != \"Not Specified\" else None\n",
    "        vacancies = None\n",
    "        if vacancies_text:\n",
    "            match = re.search(r'\\d+', vacancies_text)\n",
    "            if match:\n",
    "                vacancies = int(match.group())\n",
    "        \n",
    "        company_name_element = soup.select_one('#app > div > main > section.css-dy1y6u > div > strong.css-9geu3q > div > a')\n",
    "        company_name = company_name_element.get_text().strip() if company_name_element else \"Confidential Company\"\n",
    "\n",
    "        location_element = soup.select_one('#app > div > main > section.css-dy1y6u > div > strong.css-9geu3q')\n",
    "        location = location_element.contents[-1] if location_element else None\n",
    "\n",
    "        job_types_element = soup.select('#app > div > main > section.css-dy1y6u > div > div.css-11rcwxl > a')\n",
    "        job_types = [job_type.get_text().strip() for job_type in job_types_element] if job_types_element else None\n",
    "\n",
    "        job_skills_element = soup.select('#app > div > main > section.css-3kx5e2 > div.css-s2o0yh a')\n",
    "        job_skills = [skill.get_text().strip() for skill in job_skills_element] if job_skills_element else None\n",
    "\n",
    "        data = {\n",
    "            'job_title': [job_title],\n",
    "            'experience_needed': [experience_needed],\n",
    "            'career_level': [career_level],\n",
    "            'education_level': [education_level],\n",
    "            'min_salary': [min_salary],\n",
    "            'max_salary': [max_salary],\n",
    "            'gender': [gender],\n",
    "            'job_categories': [job_categories],\n",
    "            'job_description': [job_description],\n",
    "            'job_requirements': [job_requirements],\n",
    "            'vacancies': [vacancies],\n",
    "            'company_name': [company_name],\n",
    "            'location': [location],\n",
    "            'job_types': [job_types],\n",
    "            'job_skills': [job_skills]\n",
    "        }\n",
    "\n",
    "        current_job_df = pd.DataFrame(data)\n",
    "        \n",
    "        global job_df\n",
    "        job_df = pd.concat([job_df, current_job_df], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "    finally:\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_company_info(url):\n",
    "    driver = webdriver.Edge()\n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    try:\n",
    "        page_html = driver.page_source\n",
    "\n",
    "        soup = BeautifulSoup(page_html, 'html.parser')\n",
    "        \n",
    "        company_url_element = soup.select_one('#app > div > div:nth-child(2) > div > div > div.css-12e2e2p > div.css-aqnjlk > div > a')\n",
    "        company_url = company_url_element.get('href') if company_url_element else None\n",
    "\n",
    "        company_name_element = soup.select_one('#app > div > div:nth-child(2) > div > div > div.css-12e2e2p > div.css-1eoy87d > h1')\n",
    "        company_name = company_name_element.get_text().strip() if company_name_element else None\n",
    "\n",
    "        location_element = soup.select_one('#profile-section > div > span:-soup-contains(\"Location\") > span.css-16heon9')\n",
    "        location = location_element.get_text().strip() if location_element else None\n",
    "\n",
    "        foundation_date_element = soup.select_one('#profile-section > div > span:-soup-contains(\"Founded\") > span.css-6whuzn')\n",
    "        foundation_date = foundation_date_element.get_text().strip() if foundation_date_element else None\n",
    "        \n",
    "        size_element = soup.select_one('#profile-section > div > span:-soup-contains(\"Company Size\") > span.css-16heon9')\n",
    "        size_text = size_element.get_text().strip() if size_element else None\n",
    "        min_size = None\n",
    "        max_size = None\n",
    "        if size_text:\n",
    "            numbers = re.findall(r'\\d+', size_text)\n",
    "            if numbers:\n",
    "                min_size = numbers[0]\n",
    "                if len(numbers) > 1:\n",
    "                    max_size = numbers[1]\n",
    "\n",
    "        industry_element = soup.select_one('#profile-section > div > span:-soup-contains(\"Industry\") > span.css-16heon9')\n",
    "        industry = [indus.get_text().strip() for indus in industry_element.find_all('a')] if industry_element else None\n",
    "\n",
    "        specialities_element = soup.select_one('#profile-section > div > span:-soup-contains(\"Specialities\") > span.css-16heon9')\n",
    "        specialities = [speciality.get_text().strip() for speciality in specialities_element.find_all('a')] if specialities_element else None\n",
    "\n",
    "        try:\n",
    "            button = driver.find_element(By.CSS_SELECTOR, \"#profile-section > p > span\")\n",
    "            button.click()\n",
    "\n",
    "            p_element = driver.find_element(By.CSS_SELECTOR, \"#profile-section > p\")\n",
    "            for span_element in p_element.find_elements(By.TAG_NAME, \"span\"):\n",
    "                span_text = span_element.text\n",
    "                p_text = p_element.text\n",
    "                about = p_text.replace(span_text, '').strip()\n",
    "        except:\n",
    "            about_element = soup.select_one('#profile-section > p')\n",
    "            about = about_element.contents[0].get_text().strip() if about_element else None      \n",
    "\n",
    "        data = {\n",
    "            'company_url': [company_url],\n",
    "            'company_name': [company_name],\n",
    "            'location': [location],\n",
    "            'foundation_date': [foundation_date],\n",
    "            'min_size': [min_size],\n",
    "            'max_size': [max_size],\n",
    "            'specialities': [specialities],\n",
    "            'industry': [industry],\n",
    "            'about': [about]\n",
    "        }\n",
    "\n",
    "        current_company_df = pd.DataFrame(data)\n",
    "        \n",
    "        global company_df\n",
    "        company_df = pd.concat([company_df, current_company_df], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "    finally:\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 132):\n",
    "    loop_url = \"https://wuzzuf.net/search/jobs/?a=hpb&filters%5Broles%5D%5B0%5D=IT%2FSoftware%20Development&page=&start=\" + str(i)\n",
    "    response = requests.get(loop_url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        links = soup.find_all('a', class_=\"css-o171kl\")\n",
    "        \n",
    "        for link in links:\n",
    "            href = link.get('href')\n",
    "            if href.startswith(('http:', 'https:')):\n",
    "                extract_job_info(href)\n",
    "                http_links.append(href)\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in company_http:\n",
    "    extract_company_info(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df = job_df.dropna(subset=['job_title'])\n",
    "job_df.drop_duplicates(subset=['company_name', 'job_title'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df['Location_Part1'] = job_df['location'].str.split(', ').str[0]\n",
    "job_df['Location_Part2'] = job_df['location'].str.split(', ').str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = []\n",
    "\n",
    "for index, row in job_df.iterrows():\n",
    "    job_title = row['job_title']\n",
    "    company_name = row['company_name']\n",
    "    job_categories = row['job_categories']\n",
    "\n",
    "    if isinstance(job_categories, str):\n",
    "        job_categories = job_categories.replace('[', '').replace(']', '').replace(\"'\", \"\").split(', ')\n",
    "\n",
    "    for category in job_categories:\n",
    "        result.append({'job_title': job_title, 'company_name': company_name, 'job_category': category})\n",
    "\n",
    "job_categories_df = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = set(job_categories_df['company_name'])\n",
    "\n",
    "job = set(job_df['company_name'])\n",
    "\n",
    "missing = categories - job\n",
    "\n",
    "print(\"Company names in job_categories_df but not in job_df:\")\n",
    "print(missing)\n",
    "\n",
    "mask = job_categories_df['company_name'].isin(missing)\n",
    "\n",
    "job_categories_df = job_categories_df[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = set(job_categories_df['job_title'])\n",
    "\n",
    "job = set(job_df['job_title'])\n",
    "\n",
    "missing = categories - job\n",
    "\n",
    "print(\"Job titles in job_categories_df but not in job_df:\")\n",
    "print(missing)\n",
    "\n",
    "mask = job_categories_df['job_title'].isin(missing)\n",
    "\n",
    "job_categories_df = job_categories_df[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_categories_df.to_csv('job_categories.csv', index=False, sep='~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for index, row in job_df.iterrows():\n",
    "    job_title = row['job_title']\n",
    "    company_name = row['company_name']\n",
    "    job_types = row['job_types']\n",
    "\n",
    "    if isinstance(job_types, str):\n",
    "        job_types = job_types.replace('[', '').replace(']', '').replace(\"'\", \"\").split(', ')\n",
    "\n",
    "    for type in job_types:\n",
    "        result.append({'job_title': job_title, 'company_name': company_name, 'job_type': type})\n",
    "\n",
    "job_types_df = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = set(job_types_df['job_title'])\n",
    "\n",
    "job = set(job_df['job_title'])\n",
    "\n",
    "missing = types - job\n",
    "\n",
    "print(\"Job titles in job_types_df but not in job_df:\")\n",
    "print(missing)\n",
    "\n",
    "mask = job_types_df['job_title'].isin(missing)\n",
    "\n",
    "job_types_df = job_types_df[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = set(job_types_df['company_name'])\n",
    "\n",
    "company_company_names = set(job_df['company_name'])\n",
    "\n",
    "missing = types - company_company_names\n",
    "\n",
    "print(\"Company names in job_types_df but not in job_df:\")\n",
    "print(missing)\n",
    "\n",
    "mask = job_types_df['company_name'].isin(missing)\n",
    "\n",
    "job_types_df = job_types_df[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_types_df.to_csv('job_types.csv', index=False, sep='~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for index, row in job_df.iterrows():\n",
    "    job_title = row['job_title']\n",
    "    company_name = row['company_name']\n",
    "    job_skills = row['job_skills']\n",
    "\n",
    "    if isinstance(job_skills, str):\n",
    "        job_skills = job_skills.replace('[', '').replace(']', '').replace(\"'\", \"\").split(', ')\n",
    "\n",
    "    for skill in job_skills:\n",
    "        result.append({'job_title': job_title, 'company_name': company_name, 'job_skill': skill})\n",
    "\n",
    "job_skills_df = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = set(job_skills_df['company_name'])\n",
    "\n",
    "job = set(job_df['company_name'])\n",
    "\n",
    "missing = skills - job\n",
    "\n",
    "print(\"Company names in job_skills_df but not in job_df:\")\n",
    "print(missing)\n",
    "\n",
    "mask = job_skills_df['company_name'].isin(missing)\n",
    "\n",
    "job_skills_df = job_skills_df[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = set(job_skills_df['job_title'])\n",
    "\n",
    "job = set(job_df['job_title'])\n",
    "\n",
    "missing = skills - job\n",
    "\n",
    "print(\"Job titles names in job_df but not job_skills_df:\")\n",
    "print(missing)\n",
    "\n",
    "mask = job_skills_df['job_title'].isin(missing)\n",
    "\n",
    "job_skills_df = job_skills_df[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_skills_df['job_skill'] = job_skills_df['job_skill'].str.lower()\n",
    "job_skills_df.drop_duplicates(subset=['job_title', 'company_name', 'job_skill'], keep='first', inplace=True)\n",
    "job_skills_df.to_csv('job_skills.csv', index=False, sep='~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df.drop(columns=['location'], inplace=True)\n",
    "job_df.drop(columns=['job_categories', 'job_types', 'job_skills'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df['experience_needed'] = job_df['experience_needed'].fillna(-1)\n",
    "\n",
    "job_df['experience_needed'] = job_df['experience_needed'].astype(int)\n",
    "\n",
    "job_df['min_salary'] = job_df['min_salary'].fillna(-1)\n",
    "\n",
    "job_df['min_salary'] = job_df['min_salary'].astype(int)\n",
    "\n",
    "job_df['max_salary'] = job_df['max_salary'].fillna(-1)\n",
    "\n",
    "job_df['max_salary'] = job_df['max_salary'].astype(int)\n",
    "\n",
    "job_df['job_description'] = job_df['job_description'].str.replace(r'[\\n\\r]+', ' ', regex=True)\n",
    "\n",
    "job_df['job_requirements'] = job_df['job_requirements'].str.replace(r'[\\n\\r]+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_company_names = set(job_df['company_name'])\n",
    "\n",
    "company_company_names = set(company_df['company_name'])\n",
    "\n",
    "missing_company_names = job_company_names - company_company_names\n",
    "\n",
    "print(\"Company names in job_df but not in company_df:\")\n",
    "print(missing_company_names)\n",
    "\n",
    "mask = job_df['company_name'].isin(missing_company_names)\n",
    "\n",
    "job_df = job_df[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df.to_csv('job_postings_data_final.csv', index=False, sep='~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for index, row in company_df.iterrows():\n",
    "    company_name = row['company_name']\n",
    "    industries = row['industry']\n",
    "\n",
    "    if isinstance(industries, str) and industries:\n",
    "        industries = industries.replace('[', '').replace(']', '').replace(\"'\", \"\").split(', ')\n",
    "\n",
    "        for industry in industries:\n",
    "            result.append({'company_name': company_name, 'industry': industry})\n",
    "\n",
    "company_industries_df = pd.DataFrame(result)\n",
    "\n",
    "company_industries_df.to_csv('company_industries.csv', index=False, sep='~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in company_df.iterrows():\n",
    "    location_value = row['location']\n",
    "    if isinstance(location_value, str) and ',' in location_value:\n",
    "        parts = location_value.split(', ')\n",
    "        company_df.at[index, 'city'] = parts[0]\n",
    "        company_df.at[index, 'country'] = parts[1]\n",
    "    else:\n",
    "        company_df.at[index, 'country'] = location_value\n",
    "        company_df.at[index, 'city'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_df.drop(columns=['specialities'], inplace=True)\n",
    "\n",
    "company_df.drop(columns=['location'], inplace=True)\n",
    "\n",
    "company_df.drop(columns=['industry'], inplace=True)\n",
    "\n",
    "new_row = {\n",
    "    'company_url': [None],\n",
    "    'company_name': ['Confidential Company'],\n",
    "    'foundation_date': [None],\n",
    "    'min_size': [None],\n",
    "    'max_size': [None],\n",
    "    'about': [None],\n",
    "    'city': [None],\n",
    "    'country': [None]\n",
    "}\n",
    "\n",
    "new_row_df = pd.DataFrame(new_row)\n",
    "\n",
    "company_df = pd.concat([company_df, new_row_df], ignore_index=True)\n",
    "\n",
    "company_df['foundation_date'] = company_df['foundation_date'].fillna(-1)\n",
    "\n",
    "company_df['foundation_date'] = company_df['foundation_date'].astype(int)\n",
    "\n",
    "company_df['min_size'] = company_df['min_size'].fillna(-1)\n",
    "\n",
    "company_df['min_size'] = company_df['min_size'].astype(int)\n",
    "\n",
    "company_df['max_size'] = company_df['max_size'].fillna(-1)\n",
    "\n",
    "company_df['max_size'] = company_df['max_size'].astype(int)\n",
    "\n",
    "company_df['about'] = company_df['about'].str.replace(r'[\\n\\r]+', ' ', regex=True)\n",
    "\n",
    "company_df.to_csv('company_data_final.csv', index=False, sep='~')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MS2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
